apiVersion: v1
kind: Template
metadata:
  name: prometheus
parameters:
- description: The namespace to instantiate prometheus under. Defaults to 'default'.
  name: NAMESPACE
  value: default
objects:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
- apiVersion: v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus-cluster-reader
  roleRef:
    name: cluster-reader
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: "${NAMESPACE}"
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      name: prometheus
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    ports:
    - name: prometheus
      port: 80
      protocol: TCP
      targetPort: 9090
    selector:
      app: prometheus
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/scrape: "true"
    labels:
      name: alertmanager
    name: alertmanager
    namespace: "${NAMESPACE}"
  spec:
    ports:
    - name: alertmanager
      port: 9093
      protocol: TCP
      targetPort: 9093
    selector:
      app: alertmanager
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: prometheus
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
        name: prometheus
      spec:
        serviceAccountName: prometheus
        containers:
        - args:
          - -alertmanager.url=http://alertmanager:9093/
          - -storage.local.retention=6h
          - -storage.local.memory-chunks=500000
          - -config.file=/etc/prometheus/prometheus.yml
          image: prom/prometheus
          imagePullPolicy: IfNotPresent
          name: prometheus
          volumeMounts:
          - mountPath: /etc/prometheus
            name: config-volume
          - mountPath: /prometheus
            name: data-volume
        restartPolicy: Always
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus
          name: config-volume
        - emptyDir: {}
          name: data-volume
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: alertmanager
    name: alertmanager
    namespace: "${NAMESPACE}"
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: alertmanager
    template:
      metadata:
        labels:
          app: alertmanager
        name: alertmanager
      spec:
        serviceAccountName: prometheus
        containers:
        - args:
          - -config.file=/etc/alertmanager/alertmanager.yaml
          image: quay.io/prometheus/alertmanager
          imagePullPolicy: IfNotPresent
          name: alertmanager
          ports:
          - containerPort: 9093
            name: web
          volumeMounts:
          - mountPath: /etc/alertmanager
            name: config-volume
          - mountPath: /alertmanager
            name: data-volume
        restartPolicy: Always
        volumes:
        - configMap:
            defaultMode: 420
            name: alertmanager
          name: config-volume
        - emptyDir: {}
          name: data-volume
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: alertmanager
    namespace: "${NAMESPACE}"
  data:
    alertmanager.yaml: |
      global:
        hipchat_auth_token: E77DVnSNpdFmApVtAgaAUtLdbhFRWWdli3kmOcoE
        hipchat_url: 'https://prometheus-openshift-demo.hipchat.com/'

      route:
        receiver: team-X-hipchat

      receivers:
      - name: 'team-X-hipchat'
        hipchat_configs:
        - auth_token: E77DVnSNpdFmApVtAgaAUtLdbhFRWWdli3kmOcoE
          room_id: 3784528
          message_format: html
          notify: true
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
  data:
    prometheus.rules: |
      ALERT SecretRequestsHigh
        IF sum(apiserver_request_count{resource="secrets"}) > 10
        FOR 1s
        ANNOTATIONS {
          summary = "lots of requests for secrets. strange???",
          description = "",
        }
    prometheus.yml: |
      global:
        scrape_interval:     15s # By default, scrape targets every 15 seconds.

        # Attach these labels to any time series or alerts when communicating with
        # external systems (federation, remote storage, Alertmanager).
        external_labels:
          monitor: 'codelab-monitor'

      # A scrape configuration containing exactly one endpoint to scrape:
      # Here it's Prometheus itself.
      scrape_configs:
        # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
        - job_name: 'prometheus'

          # Override the global default and scrape targets from this job every 5 seconds.
          scrape_interval: 5s

          static_configs:
            - targets: ['localhost:9090']
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      openshift.io/host.generated: "true"
    creationTimestamp: null
    labels:
      name: prometheus
    name: prometheus
  spec:
    host: metrics-vm-48-125.eng.lab.tlv.redhat.com
    port:
      targetPort: prometheus
    to:
      kind: Service
      name: prometheus
      weight: 100
    wildcardPolicy: None
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      openshift.io/host.generated: "true"
    creationTimestamp: null
    labels:
      name: alertmanager
    name: alertmanager
  spec:
    host: alerts-vm-48-125.eng.lab.tlv.redhat.com
    port:
      targetPort: alertmanager
    to:
      kind: Service
      name: alertmanager
      weight: 100
    wildcardPolicy: None
